{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maps4u/knudtraphillers.github.io_sheep/blob/master/deus_ex_geomachina.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57BHueOiXFo8"
      },
      "source": [
        "<div style=\"background-color: white; padding: 10px;\">\n",
        "<center>\n",
        "    <img style=\"padding-right:15px\" height='50px' src=\"https://kartai.no/wp-content/uploads/2025/03/cropped-KartAi-med-partnere-2048x1145.png\">\n",
        "    <img style=\"padding-left:15px\"  height='50px' src=\"https://www.norkart.no/hubfs/norkart-logo-default.svg\">\n",
        "    </center>\n",
        "</div>\n",
        "\n",
        "# ü¶úDeus ex geomachina - L√¶r hvordan bruke spr√•kmodeller til √• f√• geomatikk-superkrefter üó∫Ô∏è\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/kartAI/deus-ex-geomachina/blob/main/deus_ex_geomachina.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "\n",
        "Hvordan unng√•r du hallusinering? Hvordan kan spr√•kmodeller gj√∏re GIS-analyser?\n",
        "\n",
        "Bli med p√• praktisk workshop der du l√¶rer √• kombinere kraften i moderne KI med geografiske data og analyser. I l√∏pet av denne sesjonen vil du:\n",
        "\n",
        "* L√¶re hvordan store spr√•kmodeller (LLMs) kan transformere og effektivisere geografiske analyser\n",
        "* F√• hands-on erfaring med √• koble ChatGPT-lignende modeller til PostGIS-databaser\n",
        "* Utforske hvordan du kan stille komplekse geografiske sp√∏rsm√•l p√• naturlig spr√•k\n",
        "* Bygge interaktive kart og visualiseringer styrt av AI\n",
        "\n",
        "Workshopen er designet for b√•de nybegynnere og erfarne geomatikere som √∏nsker √• utforske fremtidens analyseverkt√∏y. Ta med laptop og bli med p√• √• utforske der kunstig intelligens m√∏ter geografisk intelligens!\n",
        "\n",
        "Ingen tidligere KI-erfaring n√∏dvendig ‚Äì bare ta med din geomatikkunnskap, laptop og god porsjon nysgjerrighet!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-WG9XlUNXFo9"
      },
      "source": [
        "#### ‚öôÔ∏è Konfigurasjon og oppsett\n",
        "Kj√∏r cellene under."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8pn4nbIuXFo-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# load imports\n",
        "%pip install langchain-openai GeoAlchemy2 langchain_core langgraph dotenv geopandas folium matplotlib mapclassify\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DRfirwRbXFo-"
      },
      "source": [
        "**OBS! I denne cellen M√Ö du lime inn hemmeligheter du f√•r av workshop-holder**\n",
        "\n",
        "Lim inn hemmelighetene - og kj√∏r cellen."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "qzhKW2STXFo-"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://ai-geomatikkdagenesandboxhub928950591559.openai.azure.com/openai/deployments\"\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"97NTIVz4riWbZ9eeB5dBSqOpax2GUpFaSdnkdtr24qxbL9uAbdjcJQQJ99BDACfhMk5XJ3w3AAAAACOGc8Nl\"\n",
        "os.environ[\"PGCONN_STRING\"] = \"postgresql://kartai_ro:9H9PGOLT91LDzb8rYdk@kartai-postgis-dev.postgres.database.azure.com:5432/007workshop\"\n",
        "\n",
        "### Secrets from .env file\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4GKDPk5XFo-"
      },
      "source": [
        "**‚öôÔ∏è Denne cellen skal du kun kj√∏re**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rVJeJz2hXFo_"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_core.tools import tool\n",
        "import geopandas as gpd\n",
        "\n",
        "endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
        "\n",
        "# setup models: gpt4o-mini, gpt4-o, gpt3.5-turbo\n",
        "llm_gpt4o = AzureChatOpenAI(\n",
        "    azure_endpoint=f'{endpoint}/gpt-4o/chat/completions?api-version=2025-01-01-preview',\n",
        "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
        "    api_version='2025-01-01-preview'\n",
        ")\n",
        "llm_gpt4o.temperature = 0.0\n",
        "\n",
        "llm_gpt4o_mini = AzureChatOpenAI(\n",
        "    azure_endpoint=f'{endpoint}/gpt-4o-mini/chat/completions?api-version=2025-01-01-preview',\n",
        "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
        "    api_version='2025-01-01-preview'\n",
        ")\n",
        "llm_gpt4o_mini.temperature = 0.0\n",
        "\n",
        "llm_gpt35 = AzureChatOpenAI(\n",
        "    azure_endpoint=f'{endpoint}/gpt-35-turbo/chat/completions?api-version=2025-01-01-preview',\n",
        "    api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
        "    api_version='2025-01-01-preview'\n",
        ")\n",
        "llm_gpt35.temperature = 0.0\n",
        "\n",
        "### Setup the database connections\n",
        "import os\n",
        "from sqlalchemy import create_engine, inspect, MetaData, Table\n",
        "from geoalchemy2 import Geometry\n",
        "import pandas as pd\n",
        "\n",
        "# Hent tilkoblingsstreng fra milj√∏variabel og legg til 'sslmode=require'\n",
        "connection_string = os.getenv('PGCONN_STRING')\n",
        "if connection_string:\n",
        "    connection_string += \"?sslmode=require\"\n",
        "else:\n",
        "    raise EnvironmentError(\"PGCONN_STRING milj√∏variabelen mangler.\")\n",
        "\n",
        "# Opprett database-tilkobling med SQLAlchemy\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "# Funksjon for √• kj√∏re sql sp√∏rringer\n",
        "# global variable to store the result of the last operation\n",
        "gdf_result = None\n",
        "\n",
        "# Function to demonstrate how to use GeoPandas with PostGIS\n",
        "def fetch_geo_data_from_postgis(sql_query, geom_column=\"geom\"):\n",
        "    \"\"\"\n",
        "    Fetch geographic data from PostGIS database and return as GeoDataFrame\n",
        "    Stores the result as a global variable 'gdf_result' for further use in other tools.\n",
        "\n",
        "    Parameters:\n",
        "    -----------\n",
        "    sql_query : str\n",
        "        SQL query to execute against the PostGIS database\n",
        "    geom_column : str\n",
        "        Name of the geometry column in the query results\n",
        "\n",
        "    Returns:\n",
        "    --------\n",
        "    geopandas.GeoDataFrame\n",
        "        GeoDataFrame containing the query results\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Using the engine already defined in the notebook\n",
        "        gdf = gpd.read_postgis(\n",
        "            sql_query,\n",
        "            engine,  # Using the engine defined in previous cells\n",
        "            geom_col=geom_column\n",
        "        )\n",
        "        global gdf_result\n",
        "        gdf_result = gdf\n",
        "        return gdf\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching data: {e}\")\n",
        "        return None\n",
        "\n",
        "def runsql(sql):\n",
        "    return pd.read_sql(sql, engine)\n",
        "\n",
        "# # Example of how to use the function\n",
        "# sql = \"SELECT * FROM arealbruk_skogbonitet LIMIT 10\"\n",
        "# kommuner_gdf = fetch_geo_data_from_postgis(sql)\n",
        "# kommuner_gdf.explore()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vrCjkZa1XFo_"
      },
      "source": [
        "#### ü¶ú Snakk med en spr√•kmodell\n",
        "\n",
        "1. N√• skal du pr√∏ve √• kj√∏re en enkel \"prompt\" med en spr√•kmodell.\n",
        "1. Trykk kj√∏r. Da kj√∏rer en ferdig prompt \"Hvem var Eliza? Svar kort\".\n",
        "1. Ta vekk `# ` p√• de ferdige promptene i koden - s√• kan du kj√∏re automatisk.\n",
        "1. Skriv din egen prompt ved √• endre p√• teksten i `prompt = \"Hvem var Eliza?\"`\n",
        "1. Kan du f√• modellen til √• svare p√• Fransk? Farsi? Hindu?\n",
        "1. Pr√∏v ut ulike modeller. Er det forskjell? (tips: ta vekk `# ` p√• de linjene med `reponse`)\n",
        "1. F√• modellen til √• hallusinere! Skru opp temperaturen. Endre prompten.\n",
        "1. Pr√∏v √• lage en mer avansert prompt med _ROF_-malen.\n",
        "1. Du kan aktivere en input-boks ved √• ta vekk `#` fra denne linjen: `# prompt = input(\"Skriv inn prompt: \")`. Da dukker det opp et \"input-felt\" som du kan skrive inn \"prompt'en\" din. Trykk \"enter\" for √• sende til spr√•kmodellen\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BSa-ag5PXFo_",
        "outputId": "62700a08-7bae-45fa-ec95-dcfe4f4ab4fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================== GPT4o ==================================\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "\"Deus ex Geomachina\" kan tolkes som \"Gud fra geomasinen\" og er en lek med uttrykket \"Deus ex machina,\" som refererer til en uventet l√∏sning p√• et problem. I konteksten av Geomatikkdagene kan det symbolisere en genial eller uventet l√∏sning innen geomatikk, ofte ved hjelp av teknologi eller data.\n",
            "\n",
            "================================== GPT4o Mini ==================================\n",
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "\"Deus ex Geomachina\" er en lek med uttrykket \"Deus ex machina,\" som refererer til en uventet l√∏sning p√• et problem. I konteksten av Geomatikkdagene kan det tolkes som at geomatikk og teknologi fungerer som en \"gud\" eller redningsmann som l√∏ser komplekse geografiske og tekniske utfordringer.\n",
            "\n",
            "================================== GPT3.5 Turbo ==================================\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-d4ca7fd41b01>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n================================== GPT3.5 Turbo ==================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mllm_gpt35\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretty_print\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36minvoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m         return cast(\n\u001b[1;32m    306\u001b[0m             \u001b[0mChatGeneration\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             self.generate_prompt(\n\u001b[0m\u001b[1;32m    308\u001b[0m                 \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m                 \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    841\u001b[0m     ) -> LLMResult:\n\u001b[1;32m    842\u001b[0m         \u001b[0mprompt_messages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_messages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprompts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_messages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m     async def agenerate_prompt(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    681\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    682\u001b[0m                 results.append(\n\u001b[0;32m--> 683\u001b[0;31m                     self._generate_with_cache(\n\u001b[0m\u001b[1;32m    684\u001b[0m                         \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m                         \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36m_generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    906\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_manager\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 908\u001b[0;31m                 result = self._generate(\n\u001b[0m\u001b[1;32m    909\u001b[0m                     \u001b[0mmessages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_manager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    910\u001b[0m                 )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_openai/chat_models/base.py\u001b[0m in \u001b[0;36m_generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    953\u001b[0m             \u001b[0mgeneration_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"headers\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 955\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    956\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_chat_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgeneration_info\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_utils/_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    277\u001b[0m                         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing required argument: {quote(missing[0])}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 279\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    280\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/resources/chat/completions/completions.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, messages, model, audio, frequency_penalty, function_call, functions, logit_bias, logprobs, max_completion_tokens, max_tokens, metadata, modalities, n, parallel_tool_calls, prediction, presence_penalty, reasoning_effort, response_format, seed, service_tier, stop, store, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, web_search_options, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    912\u001b[0m     ) -> ChatCompletion | Stream[ChatCompletionChunk]:\n\u001b[1;32m    913\u001b[0m         \u001b[0mvalidate_response_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 914\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    915\u001b[0m             \u001b[0;34m\"/chat/completions\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    916\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1240\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m         )\n\u001b[0;32m-> 1242\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1244\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mretries_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    920\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m             \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1023\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m         return self._process_response(\n",
            "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'code': 'DeploymentNotFound', 'message': 'The API deployment for this resource does not exist. If you created the deployment within the last 5 minutes, please wait a moment and try again.'}}"
          ]
        }
      ],
      "source": [
        "#### Python code for model selection and prompting\n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "#### Disse linjene kan du aktivere (ta vekk #) hvis du vil unng√• √• skrive prompten selv\n",
        "#prompt = \"Hvem var Eliza? Svar kort\"\n",
        "prompt = \"Du er p√• Geomatikkdagene. Hva betyr Deus ex Geomachina? svar kort\"\n",
        "#prompt = \"Du er en professor i Geomatikk p√• NTNU. Hva er Geomatikk?\"\n",
        "#prompt = \"Du er elev p√• videreg√•ende. 15 √•r og snakker ungdommelig med emojier. Hva er Geomatikk?\"\n",
        "\n",
        "#### DENNE LINJEN kan du aktivere (fjerne #). Da f√•r du en \"input-boks\" du kan skrive i\n",
        "#prompt = input(\"Skriv inn prompt: \")\n",
        "\n",
        "messages = [HumanMessage(prompt)]\n",
        "\n",
        "# temperature = 0.0 gir deterministiske svar - pr√∏v √• endre temperature til 1.0 for √• f√• mer variasjon i svarene\n",
        "llm_gpt4o.temperature = 0.0\n",
        "llm_gpt4o_mini.temperature = 0.0\n",
        "llm_gpt35.temperature = 0.0\n",
        "\n",
        "print(\"\\n================================== GPT4o ==================================\")\n",
        "response = llm_gpt4o.invoke(messages)\n",
        "response.pretty_print()\n",
        "\n",
        "print(\"\\n================================== GPT4o Mini ==================================\")\n",
        "response = llm_gpt4o_mini.invoke(messages)\n",
        "response.pretty_print()\n",
        "\n",
        "print(\"\\n================================== GPT3.5 Turbo ==================================\")\n",
        "response = llm_gpt35.invoke(messages)\n",
        "response.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a3mrbdOXFo_"
      },
      "source": [
        "#### ü´° Kontroller spr√•kmodellen bedre\n",
        "Ved √• bruke system-meldinger gir vi mer kontekst til spr√•kmodellen. System-meldinger p√•virker resultatet betydelig! System-meldinger (ofte kalt \"context\") brukes i kombinasjon med brukeren sin \"prompt\".\n",
        "\n",
        "1. Pr√∏v ut ulike system-meldinger (`systemkontekst=`) og kj√∏r cellen for √• se forskjeller p√• resultatet.\n",
        "    * Legg merke til at \"kj√∏nn\" ikke finnes i datasettet.\n",
        "1. Pr√∏v √• lage ulike instrukser som strukturerer resultatene annerledes.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5PzD-ZHVXFpA",
        "outputId": "99c88a76-a5d2-483b-a6a7-75f5d00d02d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
            "\n",
            "Her er den ryddige tabellen med de spesifiserte kolonnene, der dataene er renset for feil og mangler:\n",
            "\n",
            "| ID | Navn          | Kj√∏nn | Alder | By          | Inntekt |\n",
            "|----|---------------|-------|-------|-------------|---------|\n",
            "| 1  | Ola Nordmann  | M     | 29    | Oslo        | 50000   |\n",
            "| 2  | Kari Nordmann | K     | 30    | Bergen      | 60000   |\n",
            "| 3  | Per Hansen    | M     | 45    | Ukjent      | 70000   |\n",
            "| 4  | Lise Olsen    | K     | 34    | Stavanger   | 80000   |\n",
            "| 5  | Ukjent        | M/K   | 28    | Trondheim   | 45000   |\n",
            "| 6  | Anne          | K     | Ukjent| Kristiansand | 0       |\n",
            "| 7  | Jonas         | M     | 40    | Bod√∏        | 0       |\n",
            "| 8  | Eva           | K     | 50    | Troms√∏      | 0       |\n",
            "\n",
            "**Forklaringer:**\n",
            "- Kj√∏nn er antatt basert p√• navn (M for mann, K for kvinne).\n",
            "- Alder er konvertert til tall der det er mulig, og \"ukjent\" er brukt der det ikke er spesifisert.\n",
            "- By er satt til \"Ukjent\" der det mangler informasjon.\n",
            "- Inntekt er satt til 0 der det er negative verdier eller NaN.\n"
          ]
        }
      ],
      "source": [
        "#reset temperature to 0.0 for next example\n",
        "llm_gpt4o.temperature = 0.0\n",
        "llm_gpt4o_mini.temperature = 0.0\n",
        "llm_gpt35.temperature = 0.0\n",
        "\n",
        "## prompt and output as print\n",
        "prompt = \"\"\"\n",
        "Dette er data som jeg skal rydde i. Jeg vil ha en ryddig tabell med kolonner: ID, Navn, Kj√∏nn, Alder, By, Inntekt.\n",
        "\n",
        "ID,Navn,Alder,By,Inntekt\n",
        "1,Ola Nordmann,29,Oslo,50000\n",
        "2,Kari Nordmann,Tretti,Bergen,Seksti tusen\n",
        "3,Per Hansen,45,,70000\n",
        "Fire,Lise Olsen,34,Stavanger,80000\n",
        "5, ,28,Trondheim,45000\n",
        "6,Anne,ukjent,Kristiansand,-10000\n",
        "7,Jonas,40,Bod√∏,NaN\n",
        "8,Eva,50,Troms√∏,\n",
        "\"\"\"\n",
        "\n",
        "systemkontekst = \"\"\n",
        "systemkontekst = \"Du er en ekspert p√• strukturering av komplekse data. Du gir alltid tilbake svaret som strukturert respons p√• en kortfattet m√•te. Hvis du bruker kode s√• bruker du python eller json tydelig merket med CODE <kode>. Du skal ALDRI svare noe du ikke helt sikkert kan svare p√•. Da skal du si at du ikke vet.\"\n",
        "#systemkontekst = \"Du er rotete og bakfull. Du klarer stort sett ikke gj√∏re noe riktig. Lag mer rot av alt du skal pr√∏ve √• l√∏se. Svar usammenhengende og delirisk. Gjerne hallusiner s√• mye du klarer.\"\n",
        "\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(systemkontekst),\n",
        "    HumanMessage(prompt)\n",
        "    ]\n",
        "\n",
        "response = llm_gpt4o_mini.invoke(messages)\n",
        "response.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV89WqzVXFpA"
      },
      "source": [
        "#### üìã Strukturerte datamodeller som resultat\n",
        "Her bruker vi en teknikk som heter \"tool calling\". Vi definerer en fast datamodell `Person(BaseModel)`, som vi √∏nsker resultatet tilbake som. V√•r \"prompt\" kapsles inn i en serie med kall frem og tilbake til spr√•kmodellen og python-kode. Dette s√∏rger for at vi f√•r strukturert output og reduserer kraftig potensialet for hallusinasjoner.\n",
        "\n",
        "1. Kj√∏r cellen som den er. Resultatet er en datastruktur p√• formen: `Data(people=[Person(name='Ola Nordmann', gender='Mann', age='29', city='Oslo', income='50000')])`\n",
        "1. Ta vekk `# ` p√• eksemplene i koden for √• pr√∏ve mer avanserte datainputs.\n",
        "1. Legg til egne data og pr√∏v ut ulike datamodell-definisjoner (fks splitte mellom fornavn og etternavn)\n",
        "\n",
        "Referanser:\n",
        "* https://python.langchain.com/docs/tutorials/extraction/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "R_AQX8FXXFpA",
        "outputId": "1eff675b-a392-4548-e94b-ece15e5dc04a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Data(people=[Person(name='Ola Nordmann', gender='Mann', age='29', city='Oslo', income='600000')])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "### Structured output in langchain\n",
        "\n",
        "from typing import List, Optional\n",
        "from pydantic import BaseModel, Field\n",
        "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "\n",
        "\n",
        "#### Vi lager en data-modell for √• ekstrahere data fra tabellen\n",
        "class Person(BaseModel):\n",
        "    \"\"\"Information about a person.\"\"\"\n",
        "\n",
        "    # Note that:\n",
        "    # 1. Each field is an `optional` -- this allows the model to decline to extract it!\n",
        "    # 2. Each field has a `description` -- this description is used by the LLM.\n",
        "    # Having a good description can help improve extraction results.\n",
        "    name: Optional[str] = Field(default=None, description=\"Fullt navn til personen\")\n",
        "    gender: Optional[str] = Field(default=None, description=\"Kj√∏nn. Enten 'Mann', 'Kvinne' eller 'Ukjent'\")\n",
        "    age: Optional[str] = Field(default=None, description=\"Alder i antall √•r\")\n",
        "    city: Optional[str] = Field(default=None, description=\"En by i Norge\")\n",
        "    income: Optional[str] = Field(default=None, description=\"Inntekt i norske kroner\")\n",
        "\n",
        "class Data(BaseModel):\n",
        "    \"\"\"Extracted data about people.\"\"\"\n",
        "    # Creates a model so that we can extract multiple entities.\n",
        "    people: List[Person]\n",
        "\n",
        "### Vi lager en prompt-template for √• forklare hva modellen skal gj√∏re\n",
        "prompt_template = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"You are an expert extraction algorithm. \"\n",
        "            \"Only extract relevant information from the table. \"\n",
        "            \"If you do not know the value of an attribute asked to extract, \"\n",
        "            \"guess the value or return null for the attribute's value.\",\n",
        "        ),\n",
        "        (\"human\", \"{text}\"),\n",
        "    ]\n",
        ")\n",
        "\n",
        "prompt_text = \"\"\"Jeg heter Ola Nordmann og er 29 √•r. Jeg bor i Oslo og tjener 50 000 kroner i m√•neden.\"\"\"\n",
        "\n",
        "#### Pr√∏v med flere personer\n",
        "# prompt_text = \"\"\"Jeg heter Ola Nordmann og er 29 √•r. Jeg bor i Oslo og tjener 50 000 kroner i m√•neden.\n",
        "# Kari Nordmann er tretti √•r og bor i Bergen. Hun tjener seksti tusen kroner.\n",
        "# \"\"\"\n",
        "\n",
        "#### Pr√∏v med flere personer og rotete tabelldata\n",
        "# prompt_text = \"\"\"\n",
        "# ID,Navn,Alder,By,Inntekt\n",
        "# 1,Ola Nordmann,29,Oslo,50000\n",
        "# 2,Kari Nordmann,Tretti,Bergen,Seksti tusen\n",
        "# 3,Per Hansen,45,,70000\n",
        "# Fire,Lise Olsen,34,Stavanger,80000\n",
        "# 5, ,28,Trondheim,45000\n",
        "# 6,Anne,ukjent,Kristiansand,-10000\n",
        "# 7,Jonas,40,Bod√∏,NaN\n",
        "# 8,Eva,50,Troms√∏,\n",
        "# \"\"\"\n",
        "\n",
        "structured_llm = llm_gpt4o_mini.with_structured_output(schema=Data)\n",
        "\n",
        "prompt = prompt_template.invoke({\"text\": prompt_text})\n",
        "structured_llm.invoke(prompt)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q-q6Ni7kXFpA"
      },
      "source": [
        "#### ü¶ú Spr√•k er ikke bare Norsk og Engelsk! Kode er ogs√• et spr√•k!\n",
        "Spr√•kmodeller er gode p√• alle spr√•k. Programmeringsspr√•k er intet unntak! N√• skal du f√• modellen til √• lage sm√• programmer i Python som du skal kj√∏re.\n",
        "\n",
        "Kopier koden modellen gir deg og lim inn i en ny kode-celle under. S√• kan du kj√∏re koden!\n",
        "NB! Koden er (som regel) mellom\n",
        "````\n",
        "```python\n",
        "\n",
        "```\n",
        "````\n",
        "\n",
        "1. Be modellen om √• lage python-kode som regner ut 2+2. Kopier resultatet i den tomme kode-cellen og kj√∏r den.\n",
        "1. Pr√∏v med forskjellige system-kontekster\n",
        "1. Aktiver linjene med prompten som lager et kart ( ta vekk `# `). Hvis koden ikke fungerer kan du pr√∏ve √• kj√∏re cellen p√• nytt. Blir det forskjellig?\n",
        "1. Pr√∏v ulike modeller (`llm_gpt4o_mini` og `llm_gpt35`). Er det forskjeller p√• resultatene?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "two613tsXFpA"
      },
      "outputs": [],
      "source": [
        "## prompt and output as print\n",
        "\n",
        "prompt = \"Lag python-kode som regner ut 2+2\"\n",
        "\n",
        "# prompt = \"\"\"\n",
        "# Jeg har en geojson-fil med properties: id, name, geometri. Filen er p√• denne url'en: https://raw.githubusercontent.com/robhop/fylker-og-kommuner/refs/heads/main/Kommuner-S.geojson.\n",
        "\n",
        "# Jeg har datasettet under som jeg vil lage et koropletkart av.\n",
        "\n",
        "# Datasettet er:\n",
        "\n",
        "# kommunenavn,innbyggerantall\n",
        "# ----------\n",
        "# Trondheim - Tr√•ante,205163\n",
        "# Oslo,697549\n",
        "# Bergen,283929\n",
        "# Stavanger,143574\n",
        "# √Ölesund,66\n",
        "# ----------\n",
        "\n",
        "# \"\"\"\n",
        "\n",
        "systemkontekst = \"\"\n",
        "#systemkontekst = \"Du er en GIS-ekspert og lager gyldig kode i python. Du bruker GeoPandas. Bruk gdf.explore() for √• vise et kart. Du passer godt p√• koordinatsystemer og transformasjoner. EPSG-koder som er vanlig: EPSG:4326, EPSG:25833, EPSG:25832. Gi tilbake svaret i python tydelig merket med CODE <kode>. HUSK √• ha med `%pip install` for alle pakker du bruker Du skal ALDRI svare noe du ikke helt sikkert kan svare p√•. Da skal du si at du ikke vet.\"\n",
        "#systemkontekst = \"Du er rotete og bakfull. Du klarer stort sett ikke gj√∏re noe riktig. Lag mer rot av alt du skal pr√∏ve √• l√∏se. Svar usammenhengende og delirisk. Gjerne hallusiner s√• mye du klarer.\"\n",
        "\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(systemkontekst),\n",
        "    HumanMessage(prompt)\n",
        "    ]\n",
        "\n",
        "## Gammel modell\n",
        "#response = llm_gpt35.invoke(messages)\n",
        "\n",
        "## Kraftigere modell\n",
        "response = llm_gpt4o_mini.invoke(messages)\n",
        "\n",
        "\n",
        "response.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XnUadu6vXFpA"
      },
      "source": [
        "**LIM INN KODEN DIN I CELLEN UNDER OG KJ√òR**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L5fLXOPqXFpA"
      },
      "outputs": [],
      "source": [
        "#### Her kan du lime inn koden og kj√∏re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S2UDRoXXFpA"
      },
      "source": [
        "#### üó∫Ô∏è SQL er kanskje det beste GIS-spr√•ket\n",
        "Vi er heldige og har en PostGIS-database stappfull av Norske kartdata! Men dessverre skriver ikke alle flytende SQL. N√• skal vi bruke spr√•kmodeller til √• lage SQL for oss.\n",
        "\n",
        "1. Lag en instruks som gir deg tilbake SQL (eks: regn ut 2+2 med SQL).\n",
        "1. Kopier SQL-koden spr√•kmodellen lager og bruk videre i cellene under.\n",
        "\n",
        "Pr√∏v ut:\n",
        "* Kan modellen lage geografiske data?\n",
        "* Pr√∏v ulike systemkontekster. Hvordan p√•virker det svarene?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9A_GGnWXFpB"
      },
      "outputs": [],
      "source": [
        "## prompt and output as print\n",
        "prompt = \"\"\"\n",
        "lag sql som regner ut 2+2\n",
        "\"\"\"\n",
        "\n",
        "systemkontekst = \"\"\n",
        "#systemkontekst = \"Du er en GIS-ekspert og lager gyldig kode i python. Du bruker GeoPandas. gdf.explore() gir tilbake et interaktivt kart. Du passer godt p√• koordinatsystemer og transformasjoner. EPSG-koder som er vanlig: EPSG:4326, EPSG:25833, EPSG:25832. Gi tilbake svaret i python tydelig merket med CODE <kode>. HUSK √• ha med `%pip install` for alle pakker du bruker Du skal ALDRI svare noe du ikke helt sikkert kan svare p√•. Da skal du si at du ikke vet.\"\n",
        "#systemkontekst = \"Du er rotete og bakfull. Du klarer stort sett ikke gj√∏re noe riktig. Lag mer rot av alt du skal pr√∏ve √• l√∏se. Svar usammenhengende og delirisk. Gjerne hallusiner s√• mye du klarer.\"\n",
        "\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(systemkontekst),\n",
        "    HumanMessage(prompt)\n",
        "    ]\n",
        "\n",
        "## Gammel modell - pr√∏v ut for √• se d√•rlig svar\n",
        "# response = llm_gpt35.invoke(messages)\n",
        "\n",
        "## Kraftigere modell\n",
        "response = llm_gpt4o_mini.invoke(messages)\n",
        "response.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IF87-dEsXFpB"
      },
      "source": [
        "#### ‚úÖ Validering av input med spr√•kmodeller!\n",
        "Vi kan bruke spr√•kmodeller til √• validere resultatene de selv har generert. Dette er en vanlig teknikk for √• f√• et mer korrekt sluttresultat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "grP6lMXJXFpB"
      },
      "outputs": [],
      "source": [
        "#### Validering av SQL med LLMs\n",
        "\n",
        "## HER KAN DU LIME INN SQL-KODE SOM DU VIL VALIDERE\n",
        "sql_til_validering = \"\"\"\n",
        "--SKRIV INN SQL-KODE HER\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "systemkontekst = \"Du er ekspert i SQL. Du skal validere SQL-sp√∏rringen og gi tilbakemelding om den er riktig eller ikke. Du skal ALDRI svare noe du ikke helt sikkert kan svare p√•. Da skal du si at du ikke vet. Svar tilbake kort. Gi en kort forklaring p√• hva sp√∏rringen gj√∏r og hvordan den kan bli bedre hvis den er feil.\"\n",
        "messages = [\n",
        "    SystemMessage(systemkontekst),\n",
        "    HumanMessage(sql_til_validering)\n",
        "    ]\n",
        "response = llm_gpt4o_mini.invoke(messages)\n",
        "response.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQ_sCVCjXFpB"
      },
      "source": [
        "#### üë©‚Äçüíª Kj√∏r sp√∏rringen mot databasen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27NQfF7lXFpB"
      },
      "outputs": [],
      "source": [
        "### Lim inn SQL-sp√∏rringen under og kj√∏r for √• sp√∏rre databasen og visualisere resultatet som en tabell eller kart\n",
        "sql = \"\"\"\n",
        "-- SKRIV INN SQL-KODE HER\n",
        "\n",
        "\"\"\"\n",
        "resultat = runsql(sql)\n",
        "resultat.head(10)\n",
        "\n",
        "## lag et kart av resultatet\n",
        "# resultat.explore()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IzRai0akXFpB"
      },
      "source": [
        "#### ü•∏ Gi modellen et GIS, Geomatikk og PostGIS-kurs\n",
        "\n",
        "Som du n√• vet - s√• er systemkontekst viktig. Det hjelper spr√•kmodellen √• f√• oppdatert kunnskap og informasjon som ikke var tilgjengelig n√•r modellen ble trent. GIS, Geomatikk og datamodeller i databasen v√•r kan ikke GPT-modellene s√• mye om. Under lager vi et \"kurs for spr√•kmodeller\" for akkurat v√•re datasett og teknikker i geomatikk.\n",
        "\n",
        "1. Kj√∏r kodecellen og g√• til neste celle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zbZ0BjPJXFpB"
      },
      "outputs": [],
      "source": [
        "\n",
        "systemkontekst = f\"\"\"\n",
        "Du er en GIS-ekspert med dyp kunnskap om geografiske informasjonssystemer, geomatikk og spatial analyse.\n",
        "\n",
        "Som GIS-ekspert skal du:\n",
        "- Bruke riktige EPSG-koder (EPSG:4326 for WGS84, EPSG:25833 for UTM33N i Norge)\n",
        "- Bruke spatial operasjoner korrekt (buffer, intersection, within, etc.)\n",
        "- Svare detaljert p√• SQL-sp√∏rringer med PostGIS-funksjoner\n",
        "\n",
        "V√¶r spesielt oppmerksom p√•:\n",
        "- Transformasjoner mellom koordinatsystemer\n",
        "- H√•ndtering av geometrityper (Point, LineString, Polygon)\n",
        "- Effektiv bruk av PostGIS-funksjoner for spatial analyse\n",
        "- Korrekt visualisering av geografiske data\n",
        "\n",
        "Hvis du er usikker p√• noe, si fra om det i stedet for √• gjette.\n",
        "\n",
        "## 1. Grunnleggende GIS-konsepter\n",
        "- Geografiske koordinatsystemer: WGS84 (EPSG:4326), UTM-soner (EPSG:25832, EPSG:25833 for Norge)\n",
        "- Vektordata: punkter, linjer, polygoner, multipolygoner\n",
        "- Topologi: relasjoner mellom geometriske objekter (tilst√∏tende, inneholder, krysser)\n",
        "\n",
        "## 2. PostGIS-spesifikk kunnskap\n",
        "- PostGIS er en utvidelse for PostgreSQL som h√•ndterer geografiske data\n",
        "- Romlige datatyper: POINT, LINESTRING, POLYGON, MULTIPOINT, MULTILINESTRING, MULTIPOLYGON\n",
        "- Geografiske operasjoner: ST_Distance, ST_Intersects, ST_Contains, ST_Within, ST_Buffer\n",
        "- Koordinatsystemtransformasjoner: ST_Transform(geom, srid)\n",
        "- Aggregeringsfunksjoner: ST_Union, ST_Collect\n",
        "- Topologiske relasjoner: ST_Touches, ST_Overlaps, ST_Disjoint\n",
        "\n",
        "## 3. Vanlige GIS-analyser\n",
        "- Bufferanalyse: Lage soner rundt objekter (ST_Buffer)\n",
        "- Overlappanalyse: Finne hvor geografiske lag overlapper (ST_Intersection)\n",
        "- N√¶rhetss√∏k: Finne objekter innen en viss avstand (ST_DWithin)\n",
        "- Romlig aggregering: Sl√• sammen tilst√∏tende polygoner (ST_Union)\n",
        "- Rutenettanalyser: ST_Hexagon, ST_SquareGrid for √• lage regul√¶re rutenett\n",
        "- H√∏ydeanalyser: Bratt terreng, helning, eksposisjon\n",
        "\n",
        "ALLTID lag en kolonne i SQL'en som heter 'geom' og beholder originalgeometrien.\n",
        "\n",
        "PostGIS-databasen inneholder f√∏lgende tabeller:\n",
        "- buildings\n",
        "  Kolonner:\n",
        "    - gid: INTEGER\n",
        "    - osm_id: VARCHAR\n",
        "    - code: INTEGER\n",
        "    - fclass: VARCHAR\n",
        "    - name: VARCHAR\n",
        "    - type: VARCHAR\n",
        "    - geom: geometry(MULTIPOLYGON,25833)\n",
        "- arealbruk_skogbonitet --treslag fra ar50\n",
        "  Kolonner:\n",
        "    - gid: INTEGER\n",
        "    - artype: INTEGER\n",
        "    - arskogbon: INTEGER\n",
        "    - artreslag: INTEGER --31=Barskog; 32=Lauvskog; 33=Blandingsskog\n",
        "    - arjordbr: INTEGER\n",
        "    - arveget: INTEGER\n",
        "    - areal: DOUBLE PRECISION\n",
        "    - arkartstd: VARCHAR\n",
        "    - kilde: VARCHAR\n",
        "    - geom: geometry(MULTIPOLYGON,25833)\n",
        "- flomsoner\n",
        "  Kolonner:\n",
        "    - gid: INTEGER\n",
        "    - objid: INTEGER\n",
        "    - objtype: VARCHAR\n",
        "    - lavpunkt: INTEGER\n",
        "    - gjentaksintervall: INTEGER\n",
        "    - forstedigitaliseringsdato: TIMESTAMP\n",
        "    - noyaktighet: INTEGER\n",
        "    - noyaktighethoyde: VARCHAR\n",
        "    - statusdato: TIMESTAMP\n",
        "    - flomsoneid: VARCHAR\n",
        "    - lokalid: VARCHAR\n",
        "    - navnerom: VARCHAR\n",
        "    - versjonid: VARCHAR\n",
        "    - datauttaksdato: TIMESTAMP\n",
        "    - opphav: VARCHAR\n",
        "    - symbolflom: INTEGER\n",
        "    - malemetode: INTEGER\n",
        "    - malemetodehoyde: VARCHAR\n",
        "    - statuskartlegging: VARCHAR\n",
        "    - shape_length: DOUBLE PRECISION\n",
        "    - shape_area: DOUBLE PRECISION\n",
        "    - geom: geometry(MULTIPOLYGON,25833)\n",
        "- sykkelrute_senterlinje --sykkelruter\n",
        "  Kolonner:\n",
        "    - gid: INTEGER\n",
        "    - objtype: VARCHAR\n",
        "    - skilting: VARCHAR\n",
        "    - anleggsnummer: VARCHAR\n",
        "    - uukoblingsid: VARCHAR\n",
        "    - belysning: VARCHAR\n",
        "    - lokalid: VARCHAR\n",
        "    - navnerom: VARCHAR\n",
        "    - versjonid: VARCHAR\n",
        "    - datafangstdato: TIMESTAMP\n",
        "    - oppdateringsdato: TIMESTAMP\n",
        "    - noyaktighet: INTEGER\n",
        "    - opphav: VARCHAR\n",
        "    - omradeid: INTEGER\n",
        "    - originaldatavert: VARCHAR\n",
        "    - kopidato: TIMESTAMP\n",
        "    - informasjon: VARCHAR\n",
        "    - merking: VARCHAR\n",
        "    - rutefolger: VARCHAR\n",
        "    - underlagstype: INTEGER\n",
        "    - rutebredde: INTEGER\n",
        "    - trafikkbelastning: INTEGER\n",
        "    - sesong: VARCHAR\n",
        "    - malemetode: INTEGER\n",
        "    - shape_length: DOUBLE PRECISION\n",
        "    - geom: geometry(MULTILINESTRING,25833)\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQGc8-HrXFpB"
      },
      "source": [
        "#### üó∫Ô∏èüë©‚Äçüíª F√• modellen til √• gj√∏re GIS-analyser\n",
        "\n",
        "Databasen v√•r har Flomsoner, Skogtyper, Bygninger, Sykkelruter for hele Norge. N√• kan du f√• lagd SQL med ganske avanserte GIS-analyser. Du m√• kopiere SQL-koden som spr√•kmodellen lager til cellen under for √• kj√∏re sp√∏rringen mot databasen. Databasen har mye data og er en liten server. Det betyr at noen sp√∏rringer kan ta lang tid. Pr√∏v √• bruke \"validering av SQL\"-cellen som vi brukte tidligere for √• validere SQL-koden.\n",
        "\n",
        "Eksempler p√• prompts du kan pr√∏ve:\n",
        "* \"Finn ti steder med lauvskog\"\n",
        "* \"Finn ti steder med Bj√∏rk\"\n",
        "* \"Finn de 10 st√∏rste flomsonene i areal\"\n",
        "* \"Finn 10 bygninger. Hvilken skogtype er i n√¶rheten? Jeg vil ha tilbake geometrien til bygninger\"\n",
        "* \"Hvilke bygninger er innenfor 100 meter av den st√∏rste flomsonen?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dRQm2K4jXFpB"
      },
      "outputs": [],
      "source": [
        "## prompt and output as print\n",
        "prompt = \"\"\"\n",
        "Finn ti steder med lauvskog\n",
        "\"\"\"\n",
        "#finn de 10 st√∏rste flomsonene i areal. Gi tilbake SQL-sp√∏rringen som gir resultatet.\n",
        "\n",
        "messages = [\n",
        "    SystemMessage(systemkontekst),\n",
        "    HumanMessage(prompt)\n",
        "    ]\n",
        "\n",
        "## Gammel modell\n",
        "#response = llm_gpt35.invoke(messages)\n",
        "\n",
        "## Kraftigere modell\n",
        "response = llm_gpt4o.invoke(messages)\n",
        "response.pretty_print()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIZSXmz4XFpC"
      },
      "source": [
        "#### ‚úÖ Validering av input med spr√•kmodeller!\n",
        "Bruk valideringsmetoden for √• f√• syntaks-sjekk, kontroll og forklaring p√• SQL-koden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6XJe52DJXFpC"
      },
      "outputs": [],
      "source": [
        "#### Validering av SQL med LLMs\n",
        "\n",
        "## HER KAN DU LIME INN SQL-KODE SOM DU VIL VALIDERE\n",
        "sql_til_validering = \"\"\"\n",
        "--SKRIV INN SQL-KODE HER\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "systemkontekst = \"Du er ekspert i SQL. Du skal validere SQL-sp√∏rringen og gi tilbakemelding om den er riktig eller ikke. Gj√∏r en vurdering av kompleksitet og kj√∏retid av SQL'en. Du skal ALDRI svare noe du ikke helt sikkert kan svare p√•. Da skal du si at du ikke vet. Svar tilbake kort. Gi en kort forklaring p√• hva sp√∏rringen gj√∏r og hvordan den kan bli bedre hvis den er feil.\"\n",
        "messages = [\n",
        "    SystemMessage(systemkontekst),\n",
        "    HumanMessage(sql_til_validering)\n",
        "    ]\n",
        "response = llm_gpt4o_mini.invoke(messages)\n",
        "response.pretty_print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PyxAO7RXFpC"
      },
      "source": [
        "#### üíª Kj√∏r SQL'en du fikk generert!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IaXytQhqXFpC"
      },
      "outputs": [],
      "source": [
        "# Example of how to use the function\n",
        "sql = \"\"\"\n",
        "-- SKRIV INN SQL-KODE HER\n",
        "\n",
        "\"\"\"\n",
        "resultat = fetch_geo_data_from_postgis(sql)\n",
        "sample = resultat.head()\n",
        "#print(sample)\n",
        "\n",
        "## lag et kart av resultatet\n",
        "resultat.explore()\n",
        "#resultat.explore(width=500 , height=500)\n",
        "\n",
        "### Lagre som geojson-fil\n",
        "#resultat.to_crs('4326').to_file('./resulta2t.geojson', driver=\"GeoJSON\")\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "geo_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.0"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}